{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a40038d-2066-48ad-81a0-cccb2c76c106",
   "metadata": {},
   "source": [
    "### Handling imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49eef640-6476-4dc8-9ffd-f8dde56fabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a92f87-6995-4a27-a749-48b0eaf47003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon never tried explain still stare ...         1\n",
       "1  buddhism much lot compatible christianity espe...         1\n",
       "2  seriously say thing first get complex explain ...        -1\n",
       "3  learned want teach different focus goal not wr...         0\n",
       "4  benefit may want read living buddha living chr...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./preprocessed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff546e66-67b1-44cf-ab76-3d3171e2e6d0",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f61166-7f36-48cb-b247-b130a648b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a8860b-7a02-4291-9cc5-086e66940e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c1fb2-3c40-48c6-8b3a-3ba887d61dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "import pickle\n",
    "import dagshub\n",
    "\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab428f-20c4-4aff-b4f6-07619ae5c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as shreekoshti199\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as shreekoshti199\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"shreekoshti199/YouTube-Sentiment-Insights-Plugin\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"shreekoshti199/YouTube-Sentiment-Insights-Plugin\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository shreekoshti199/YouTube-Sentiment-Insights-Plugin initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository shreekoshti199/YouTube-Sentiment-Insights-Plugin initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "username = os.getenv(\"DAGSHUB_USERNAME\")\n",
    "token = os.getenv(\"DAGSHUB_TOKEN\")\n",
    "\n",
    "if not username or not token:\n",
    "    raise ValueError(\"Missing DagsHub credentials in environment variables\")\n",
    "\n",
    "# Construct the authenticated MLflow tracking URI\n",
    "mlflow_uri = f\"https://{username}:{token}@dagshub.com/{username}/YouTube-Sentiment-Insights-Plugin.mlflow\"\n",
    "\n",
    "dagshub.init(repo_owner=username, repo_name=\"YouTube-Sentiment-Insights-Plugin\", mlflow=True)\n",
    "mlflow.set_tracking_uri(mlflow_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570c1864-e459-48b5-bd58-4a53072bceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 02:56:59 INFO mlflow.tracking.fluent: Experiment with name 'Exp 4 - Handling Imbalanced Data' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/5060d452563b4218ad886674d1c4a697', creation_time=1760736422348, experiment_id='11', last_update_time=1760736422348, lifecycle_stage='active', name='Exp 4 - Handling Imbalanced Data', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "# Set or create an experiment\n",
    "experiment = 'Exp 4 - Handling Imbalanced Data'\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03270ee-27f1-45cb-9566-a708d99d4328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 03:01:50,131 - INFO - Starting MLFlow run ....\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info(\"Starting MLFlow run ....\")\n",
    "\n",
    "def run_experiment(imbalance_method):\n",
    "    # TF-IDF Params\n",
    "    ngram_range = (1, 3)  \n",
    "    vec_max_features = 1000\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Initialize the Vectorizer\n",
    "        logging.info(\"Initialize Vectorizer ....\")\n",
    "        \n",
    "        vec = TfidfVectorizer(ngram_range=ngram_range, max_features=vec_max_features)\n",
    "    \n",
    "        # Train-Test Split\n",
    "        logging.info(\"Train test split ....\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df['clean_comment'], df['category'], \n",
    "            test_size=0.2, random_state=42, stratify=df['category']\n",
    "        )\n",
    "    \n",
    "        # Text Vectorization\n",
    "        logging.info(\"Vectorizing the X_train & X_test ....\")\n",
    "        \n",
    "        X_train_vec = vec.fit_transform(X_train)\n",
    "        X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    \n",
    "        # Handle class imbalance based on the selected method (only applied to the training set)\n",
    "        logging.info(\"Initialize the Data Balancing method ....\")\n",
    "        \n",
    "        if imbalance_method == 'class_weights':\n",
    "            # Use class_weight in Random Forest\n",
    "            class_weight = 'balanced'\n",
    "        else:\n",
    "            class_weight = None  # Do not apply class_weight if using resampling\n",
    "            \n",
    "            # Resampling Techniques (only apply to the training set)\n",
    "            if imbalance_method == 'oversampling':\n",
    "                smote = SMOTE(random_state=42)\n",
    "                X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "            elif imbalance_method == 'adasyn':\n",
    "                adasyn = ADASYN(random_state=42)\n",
    "                X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "            elif imbalance_method == 'undersampling':\n",
    "                rus = RandomUnderSampler(random_state=42)\n",
    "                X_train_vec, y_train = rus.fit_resample(X_train_vec, y_train)\n",
    "            elif imbalance_method == 'smote_enn':\n",
    "                smote_enn = SMOTEENN(random_state=42)\n",
    "                X_train_vec, y_train = smote_enn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "        try: \n",
    "            # Start MLflow Run\n",
    "            with mlflow.start_run() as run:\n",
    "                \n",
    "                # ------------------ Metadata ------------------\n",
    "                logging.info(\"Logging Metadata ....\")\n",
    "                \n",
    "                mlflow.set_tag('mlflow.runName', f'Imbalance_{imbalance_method}_RandomForest_TFIDF_TriGrams')\n",
    "                mlflow.set_tag('experiment_type', 'imbalance_handling')\n",
    "                mlflow.set_tag('model_type', 'RandomForestClassifier')\n",
    "                mlflow.set_tag('description', f\"RandomForest with TF-IDF BIgrams, imbalance handling method={imbalance_method}\")\n",
    "        \n",
    "                # ------------------ Log Vectorizer Params ------------------\n",
    "                logging.info(\"Logging Vectorizer Params ....\")\n",
    "                \n",
    "                mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
    "                mlflow.log_param(\"ngram_range\", ngram_range)\n",
    "                mlflow.log_param(\"vectorizer_max_features\", vec_max_features)\n",
    "        \n",
    "                # ------------------ Log Model Params ------------------\n",
    "                logging.info(\"Logging Model Params ....\")\n",
    "                \n",
    "                n_estimators = 200\n",
    "                max_depth = 15\n",
    "                mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "                mlflow.log_param(\"max_depth\", max_depth)\n",
    "                mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
    "        \n",
    "                # ------------------ Train Model ------------------\n",
    "                logging.info(\"Model Training & Predicion Started ....\")\n",
    "                \n",
    "                model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "                model.fit(X_train_vec, y_train)\n",
    "        \n",
    "                # ------------------ Predictions ------------------\n",
    "                y_pred = model.predict(X_test_vec)\n",
    "\n",
    "                logging.info(\"Model Training & Predicion Ended ....\")\n",
    "                \n",
    "                # ------------------ Metrics ------------------\n",
    "                logging.info(\"Logging Metrics ....\")\n",
    "                \n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "                # Log classification report\n",
    "                classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "                for label, metrics in classification_rep.items():\n",
    "                    if isinstance(metrics, dict):\n",
    "                        for metric, value in metrics.items():\n",
    "                            mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "            \n",
    "                # ------------------ Confusion Matrix ------------------\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"Actual\")\n",
    "                plt.title(\"Confusion Matrix\")\n",
    "                plt.tight_layout()\n",
    "        \n",
    "                mlflow.log_figure(plt.gcf(), \"Confusion_Matrix.png\")  # log the plot\n",
    "                plt.close()\n",
    "                \n",
    "                # ------------------ Log the Model Properly ------------------\n",
    "                logging.info(\"Logging the model ....\")\n",
    "                \n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"model\",  # will create artifacts/model folder\n",
    "                    # registered_model_name=f\"rfc_TFIDF_BIgram_{vec_max_features}\"\n",
    "                )\n",
    "        \n",
    "                end_time = time.time()\n",
    "        \n",
    "                logging.info(f\"Completed the Experiment in {end_time-start_time} seconds\")\n",
    "        \n",
    "                logging.info(f\"Accuracy -> {accuracy:.2f}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error occured while Model Trainig: {e}\")\n",
    "            raise\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occured while Vectorizing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b2dafb-1ce1-4f1e-85b8-cd07c3df0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 03:01:52,865 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 03:01:52,865 - INFO - Train test split ....\n",
      "2025-10-18 03:01:52,883 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 03:01:57,215 - INFO - Initialize the Data Balancing method ....\n",
      "2025-10-18 03:01:58,623 - INFO - Logging Metadata ....\n",
      "2025-10-18 03:02:00,102 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 03:02:01,183 - INFO - Logging Model Params ....\n",
      "2025-10-18 03:02:02,251 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 03:02:08,616 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 03:02:08,616 - INFO - Logging Metrics ....\n",
      "2025-10-18 03:02:21,742 - INFO - Logging the model ....\n",
      "2025-10-18 03:03:12,867 - INFO - Completed the Experiment in 80.00163078308105 seconds\n",
      "2025-10-18 03:03:12,867 - INFO - Accuracy -> 0.67\n",
      "2025-10-18 03:03:13,262 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 03:03:13,262 - INFO - Train test split ....\n",
      "2025-10-18 03:03:13,297 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 03:03:17,514 - INFO - Initialize the Data Balancing method ....\n",
      "2025-10-18 03:03:20,429 - INFO - Logging Metadata ....\n",
      "2025-10-18 03:03:21,892 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 03:03:22,976 - INFO - Logging Model Params ....\n",
      "2025-10-18 03:03:24,242 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 03:03:31,630 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 03:03:31,630 - INFO - Logging Metrics ....\n",
      "2025-10-18 03:03:44,133 - INFO - Logging the model ....\n",
      "2025-10-18 03:04:40,834 - INFO - Completed the Experiment in 87.5716004371643 seconds\n",
      "2025-10-18 03:04:40,849 - INFO - Accuracy -> 0.68\n",
      "2025-10-18 03:04:41,320 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 03:04:41,320 - INFO - Train test split ....\n",
      "2025-10-18 03:04:41,346 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 03:04:45,553 - INFO - Initialize the Data Balancing method ....\n",
      "2025-10-18 03:04:57,272 - INFO - Logging Metadata ....\n",
      "2025-10-18 03:04:58,754 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 03:04:59,851 - INFO - Logging Model Params ....\n",
      "2025-10-18 03:05:00,945 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 03:05:08,179 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 03:05:08,179 - INFO - Logging Metrics ....\n",
      "2025-10-18 03:05:20,706 - INFO - Logging the model ....\n",
      "2025-10-18 03:06:15,790 - INFO - Completed the Experiment in 94.46965336799622 seconds\n",
      "2025-10-18 03:06:15,790 - INFO - Accuracy -> 0.68\n",
      "2025-10-18 03:06:16,147 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 03:06:16,147 - INFO - Train test split ....\n",
      "2025-10-18 03:06:16,166 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 03:06:20,615 - INFO - Initialize the Data Balancing method ....\n",
      "2025-10-18 03:06:21,011 - INFO - Logging Metadata ....\n",
      "2025-10-18 03:06:22,366 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 03:06:23,435 - INFO - Logging Model Params ....\n",
      "2025-10-18 03:06:24,459 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 03:06:28,334 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 03:06:28,334 - INFO - Logging Metrics ....\n",
      "2025-10-18 03:06:44,131 - INFO - Logging the model ....\n",
      "2025-10-18 03:07:28,677 - INFO - Completed the Experiment in 72.53076815605164 seconds\n",
      "2025-10-18 03:07:28,677 - INFO - Accuracy -> 0.67\n",
      "2025-10-18 03:07:29,037 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 03:07:29,037 - INFO - Train test split ....\n",
      "2025-10-18 03:07:29,065 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 03:07:33,544 - INFO - Initialize the Data Balancing method ....\n",
      "2025-10-18 03:08:01,767 - INFO - Logging Metadata ....\n",
      "2025-10-18 03:08:03,224 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 03:08:04,303 - INFO - Logging Model Params ....\n",
      "2025-10-18 03:08:05,349 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 03:08:07,875 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 03:08:07,875 - INFO - Logging Metrics ....\n",
      "2025-10-18 03:08:24,926 - INFO - Logging the model ....\n",
      "2025-10-18 03:08:51,631 - INFO - Completed the Experiment in 82.59408235549927 seconds\n",
      "2025-10-18 03:08:51,631 - INFO - Accuracy -> 0.45\n"
     ]
    }
   ],
   "source": [
    "# Run 5 Experiments Results on MLFlow\n",
    "imbalance_methods = ['class_weights', 'oversampling', 'adasyn', 'undersampling', 'smote_enn']\n",
    "\n",
    "for method in imbalance_methods:\n",
    "    # TF-IDF Experiments\n",
    "    run_experiment(imbalance_method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f465da-f753-4f20-b35f-b3ef80e9e3c2",
   "metadata": {},
   "source": [
    "## Experiment 4 – Handling Class Imbalance\n",
    "\n",
    "### Objective\n",
    "To analyze how different **class imbalance handling methods** affect the performance of the **RandomForestClassifier** trained on TF-IDF features.\n",
    "\n",
    "### Experiment Setup\n",
    "- **Model:** RandomForestClassifier  \n",
    "- **Vectorizer:** TF-IDF (ngram_range = (1,2), max_features = 2000)  \n",
    "- **Imbalance handling methods tested:**\n",
    "  - SMOTE-ENN\n",
    "  - Random Undersampling\n",
    "  - ADASYN\n",
    "  - Random Oversampling\n",
    "  - Class Weights (`balanced` parameter in RandomForest)\n",
    "- **Metrics logged:** Accuracy, Precision, Recall, F1-score (per class and weighted average)  \n",
    "\n",
    "---\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Imbalance Method | Accuracy | Weighted F1-score | -1 F1-score | 1 F1-score |\n",
    "|------------------|-----------|------------------|-------------|-------------|\n",
    "| SMOTE-ENN        | 0.672     | 0.665            | 0.469       | 0.002       |\n",
    "| Undersampling    | 0.674     | 0.664            | 0.534       | 0.685       |\n",
    "| ADASYN           | 0.674     | 0.666            | 0.509       | 0.693       |\n",
    "| Oversampling     | 0.674     | 0.666            | 0.519       | 0.692       |\n",
    "| Class Weights    | 0.657     | 0.607            | 0.218       | 0.711       |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "- **ADASYN** and **Random Oversampling** provided the **best overall performance**, both achieving **0.674 accuracy** and **0.666 weighted F1-score**.  \n",
    "- **Class Weights** alone did not improve minority class recall (-1 class) significantly, although it performed well for the positive class (1).  \n",
    "- **SMOTE-ENN**, while effective for recall of class -1, led to extremely poor results for class 1, likely due to data noise introduced during ENN cleaning.  \n",
    "- **Undersampling** achieved balanced but slightly lower macro F1 compared to ADASYN and Oversampling.\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations / Next Steps\n",
    "- Use **ADASYN** or **Random Oversampling** as the preferred imbalance handling strategy.  \n",
    "- Next experiment: Combine **ADASYN** with **hyperparameter tuning** (e.g., n_estimators, max_depth).  \n",
    "- Evaluate using **confusion matrices** and **ROC-AUC** to better understand class-wise trade-offs.  \n",
    "- Consider experimenting with **XGBoost or LightGBM** with built-in class imbalance handling options.\n",
    "\n",
    "---\n",
    "\n",
    "### Artifacts\n",
    "- MLflow logs for imbalance methods  \n",
    "- Confusion matrix visualizations  \n",
    "- Feature importance comparison across imbalance methods  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd37ebb-f45e-4a4b-8e2b-8f40a1d81abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube-comment_Experiments",
   "language": "python",
   "name": "youtube-comment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
