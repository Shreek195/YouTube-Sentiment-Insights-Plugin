{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6fb65a-8b4a-41b0-b44a-19018910db68",
   "metadata": {},
   "source": [
    "### How many max features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0032eedb-6a9f-4ee2-90d6-27f00077b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9748d640-18fa-4cec-a653-5d997c307d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon never tried explain still stare ...         1\n",
       "1  buddhism much lot compatible christianity espe...         1\n",
       "2  seriously say thing first get complex explain ...        -1\n",
       "3  learned want teach different focus goal not wr...         0\n",
       "4  benefit may want read living buddha living chr...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./preprocessed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660a053-bfab-4dbe-9017-0bff8198ef10",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38912925-893f-465d-a4e2-2d9ee561a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e0a26-bc59-4282-b3b6-ff262133236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "import pickle\n",
    "import dagshub\n",
    "\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54f7d2-afbf-4de1-b19b-e0f0f4e1e32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as shreekoshti199\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as shreekoshti199\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"shreekoshti199/YouTube-Sentiment-Insights-Plugin\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"shreekoshti199/YouTube-Sentiment-Insights-Plugin\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository shreekoshti199/YouTube-Sentiment-Insights-Plugin initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository shreekoshti199/YouTube-Sentiment-Insights-Plugin initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "username = os.getenv(\"DAGSHUB_USERNAME\")\n",
    "token = os.getenv(\"DAGSHUB_TOKEN\")\n",
    "\n",
    "if not username or not token:\n",
    "    raise ValueError(\"Missing DagsHub credentials in environment variables\")\n",
    "\n",
    "# Construct the authenticated MLflow tracking URI\n",
    "mlflow_uri = f\"https://{username}:{token}@dagshub.com/{username}/YouTube-Sentiment-Insights-Plugin.mlflow\"\n",
    "\n",
    "dagshub.init(repo_owner=username, repo_name=\"YouTube-Sentiment-Insights-Plugin\", mlflow=True)\n",
    "mlflow.set_tracking_uri(mlflow_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3929f84-202a-426c-bc6e-df2f2703ad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4f6dd3dd818943c7bbcbba49a221fe88', creation_time=1760735056124, experiment_id='10', last_update_time=1760735056124, lifecycle_stage='active', name='Exp 3 - TfIdf Trigram max_features', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "experiment = 'Exp 3 - TfIdf Trigram max_features'\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273afa07-ad25-409e-9271-080e82e91174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 02:41:26,823 - INFO - Starting MLFlow run ....\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info(\"Starting MLFlow run ....\")\n",
    "\n",
    "def run_experiment(vec_max_features):\n",
    "    ngram_range = (1, 3)  # Trigram setting\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Initialize the Vectorizer\n",
    "        logging.info(\"Initialize Vectorizer ....\")\n",
    "        \n",
    "        vec = TfidfVectorizer(ngram_range=ngram_range, max_features=vec_max_features)\n",
    "    \n",
    "        # Train-Test Split\n",
    "        logging.info(\"Train test split ....\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df['clean_comment'], df['category'], \n",
    "            test_size=0.2, random_state=42, stratify=df['category']\n",
    "        )\n",
    "    \n",
    "        # Text Vectorization\n",
    "        logging.info(\"Vectorizing the X_train & X_test ....\")\n",
    "        \n",
    "        X_train = vec.fit_transform(X_train)\n",
    "        X_test = vec.transform(X_test)\n",
    "\n",
    "        try: \n",
    "            # Start MLflow Run\n",
    "            with mlflow.start_run() as run:\n",
    "                \n",
    "                # ------------------ Metadata ------------------\n",
    "                logging.info(\"Logging Metadata ....\")\n",
    "                \n",
    "                mlflow.set_tag('mlflow.runName', f'TFIDF_TriGrams_max_features_{vec_max_features}')\n",
    "                mlflow.set_tag('experiment_type', 'feature_engineering')\n",
    "                mlflow.set_tag('model_type', 'RandomForestClassifier')\n",
    "                mlflow.set_tag('description', f\"RandomForest with TF-IDF TriGrams, max_features={vec_max_features}\")\n",
    "        \n",
    "                # ------------------ Log Vectorizer Params ------------------\n",
    "                logging.info(\"Logging Vectorizer Params ....\")\n",
    "                \n",
    "                mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
    "                mlflow.log_param(\"ngram_range\", ngram_range)\n",
    "                mlflow.log_param(\"vectorizer_max_features\", vec_max_features)\n",
    "        \n",
    "                # ------------------ Log Model Params ------------------\n",
    "                logging.info(\"Logging Model Params ....\")\n",
    "                \n",
    "                n_estimators = 200\n",
    "                max_depth = 15\n",
    "                mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "                mlflow.log_param(\"max_depth\", max_depth)\n",
    "                \n",
    "                # ------------------ Train Model ------------------\n",
    "                logging.info(\"Model Training & Predicion Started ....\")\n",
    "                \n",
    "                model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "        \n",
    "                # ------------------ Predictions ------------------\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                logging.info(\"Model Training & Predicion Ended ....\")\n",
    "        \n",
    "                # ------------------ Metrics ------------------\n",
    "                logging.info(\"Logging Metrics ....\")\n",
    "                \n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "                # Log classification report\n",
    "                classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "                for label, metrics in classification_rep.items():\n",
    "                    if isinstance(metrics, dict):\n",
    "                        for metric, value in metrics.items():\n",
    "                            mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "            \n",
    "                # ------------------ Confusion Matrix ------------------\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"Actual\")\n",
    "                plt.title(\"Confusion Matrix\")\n",
    "                plt.tight_layout()\n",
    "        \n",
    "                mlflow.log_figure(plt.gcf(), \"Confusion_Matrix.png\")  # log the plot\n",
    "                plt.close()\n",
    "        \n",
    "                # ------------------ Log the Model Properly ------------------\n",
    "                logging.info(\"Logging the model ....\")\n",
    "                \n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"model\",  # will create artifacts/model folder\n",
    "                    # registered_model_name=f\"rfc_TFIDF_BIgram_{vec_max_features}\"\n",
    "                )\n",
    "        \n",
    "                end_time = time.time()\n",
    "\n",
    "                logging.info(f\"Completed the Experiment in {end_time-start_time} seconds\")\n",
    "        \n",
    "                logging.info(f\"Accuracy -> {accuracy:.2f}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error occured while Model Trainig: {e}\")\n",
    "            raise\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occured while Vectorizing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f93b681-48a9-425a-ac04-cf7588cb4c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 02:41:26,828 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:41:26,828 - INFO - Train test split ....\n",
      "2025-10-18 02:41:26,847 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:41:31,961 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:41:33,450 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:41:34,504 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:41:35,230 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:41:40,865 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:41:40,865 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:41:54,095 - INFO - Logging the model ....\n",
      "2025-10-18 02:42:44,798 - INFO - Completed the Experiment in 77.96922636032104 seconds\n",
      "2025-10-18 02:42:44,798 - INFO - Accuracy -> 0.67\n",
      "2025-10-18 02:42:45,185 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:42:45,201 - INFO - Train test split ....\n",
      "2025-10-18 02:42:45,239 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:42:49,890 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:42:51,335 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:42:52,375 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:42:53,098 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:42:58,172 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:42:58,172 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:43:12,023 - INFO - Logging the model ....\n",
      "2025-10-18 02:43:57,875 - INFO - Completed the Experiment in 72.69022703170776 seconds\n",
      "2025-10-18 02:43:57,875 - INFO - Accuracy -> 0.66\n",
      "2025-10-18 02:43:58,249 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:43:58,249 - INFO - Train test split ....\n",
      "2025-10-18 02:43:58,272 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:44:02,844 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:44:04,315 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:44:05,418 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:44:06,144 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:44:10,952 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:44:10,952 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:44:24,969 - INFO - Logging the model ....\n",
      "2025-10-18 02:45:08,547 - INFO - Completed the Experiment in 70.29819941520691 seconds\n",
      "2025-10-18 02:45:08,547 - INFO - Accuracy -> 0.66\n",
      "2025-10-18 02:45:08,956 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:45:08,958 - INFO - Train test split ....\n",
      "2025-10-18 02:45:08,974 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:45:13,562 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:45:15,021 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:45:16,108 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:45:16,828 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:45:21,436 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:45:21,436 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:45:35,687 - INFO - Logging the model ....\n",
      "2025-10-18 02:46:16,361 - INFO - Completed the Experiment in 67.40430521965027 seconds\n",
      "2025-10-18 02:46:16,361 - INFO - Accuracy -> 0.65\n",
      "2025-10-18 02:46:16,749 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:46:16,749 - INFO - Train test split ....\n",
      "2025-10-18 02:46:16,788 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:46:21,500 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:46:22,953 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:46:23,992 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:46:24,701 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:46:29,263 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:46:29,263 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:46:43,655 - INFO - Logging the model ....\n",
      "2025-10-18 02:47:24,786 - INFO - Completed the Experiment in 68.03681063652039 seconds\n",
      "2025-10-18 02:47:24,786 - INFO - Accuracy -> 0.66\n",
      "2025-10-18 02:47:25,167 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:47:25,183 - INFO - Train test split ....\n",
      "2025-10-18 02:47:25,204 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:47:29,763 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:47:31,241 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:47:32,310 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:47:33,025 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:47:37,452 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:47:37,452 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:47:51,904 - INFO - Logging the model ....\n",
      "2025-10-18 02:48:31,638 - INFO - Completed the Experiment in 66.47051429748535 seconds\n",
      "2025-10-18 02:48:31,638 - INFO - Accuracy -> 0.65\n",
      "2025-10-18 02:48:32,017 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:48:32,017 - INFO - Train test split ....\n",
      "2025-10-18 02:48:32,041 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:48:36,639 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:48:38,106 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:48:39,186 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:48:39,906 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:48:44,185 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:48:44,201 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:48:58,825 - INFO - Logging the model ....\n",
      "2025-10-18 02:49:37,248 - INFO - Completed the Experiment in 65.23130941390991 seconds\n",
      "2025-10-18 02:49:37,248 - INFO - Accuracy -> 0.65\n",
      "2025-10-18 02:49:37,638 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:49:37,638 - INFO - Train test split ....\n",
      "2025-10-18 02:49:37,666 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:49:42,305 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:49:43,826 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:49:44,920 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:49:45,639 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:49:50,013 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:49:50,013 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:50:04,467 - INFO - Logging the model ....\n",
      "2025-10-18 02:50:43,331 - INFO - Completed the Experiment in 65.69378733634949 seconds\n",
      "2025-10-18 02:50:43,331 - INFO - Accuracy -> 0.65\n",
      "2025-10-18 02:50:43,747 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:50:43,747 - INFO - Train test split ....\n",
      "2025-10-18 02:50:43,773 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:50:48,341 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:50:49,840 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:50:50,929 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:50:51,654 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:50:55,934 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:50:55,934 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:51:10,513 - INFO - Logging the model ....\n",
      "2025-10-18 02:51:48,153 - INFO - Completed the Experiment in 64.40579080581665 seconds\n",
      "2025-10-18 02:51:48,169 - INFO - Accuracy -> 0.65\n",
      "2025-10-18 02:51:48,544 - INFO - Initialize Vectorizer ....\n",
      "2025-10-18 02:51:48,544 - INFO - Train test split ....\n",
      "2025-10-18 02:51:48,585 - INFO - Vectorizing the X_train & X_test ....\n",
      "2025-10-18 02:51:53,184 - INFO - Logging Metadata ....\n",
      "2025-10-18 02:51:54,653 - INFO - Logging Vectorizer Params ....\n",
      "2025-10-18 02:51:55,719 - INFO - Logging Model Params ....\n",
      "2025-10-18 02:51:56,544 - INFO - Model Training & Predicion Started ....\n",
      "2025-10-18 02:52:00,762 - INFO - Model Training & Predicion Ended ....\n",
      "2025-10-18 02:52:00,762 - INFO - Logging Metrics ....\n",
      "2025-10-18 02:52:15,294 - INFO - Logging the model ....\n",
      "2025-10-18 02:52:52,271 - INFO - Completed the Experiment in 63.726808071136475 seconds\n",
      "2025-10-18 02:52:52,271 - INFO - Accuracy -> 0.65\n"
     ]
    }
   ],
   "source": [
    "# Run 10 Experiments Results on MLFlow\n",
    "max_features_values = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "for max_features in max_features_values:\n",
    "    # TF-IDF Experiments\n",
    "    run_experiment(vec_max_features=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1a568-402b-4f61-87f5-31d3758d3758",
   "metadata": {},
   "source": [
    "## Experiment 3 – RandomForest with TF-IDF and Different Max Features\n",
    "\n",
    "### Objective\n",
    "Evaluate the effect of **`max_features`** in **TF-IDF vectorizer** (ngram_range = (1,2)) on the performance of **RandomForestClassifier** for sentiment analysis.\n",
    "\n",
    "### Experiment Setup\n",
    "- **Model:** RandomForestClassifier  \n",
    "- **Vectorizer:** TF-IDF  \n",
    "- **N-gram range:** (1,2)  \n",
    "- **Max features tested:** 10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000, 1000  \n",
    "- **Metrics logged:** Accuracy, Precision, Recall, F1-score (per class and weighted average)  \n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Max Features | Accuracy | Weighted F1-score |\n",
    "|--------------|----------|-----------------|\n",
    "| 10000        | 0.635    | 0.557           |\n",
    "| 9000         | 0.638    | 0.561           |\n",
    "| 8000         | 0.641    | 0.564           |\n",
    "| 7000         | 0.643    | 0.566           |\n",
    "| 6000         | 0.640    | 0.564           |\n",
    "| 5000         | 0.646    | 0.571           |\n",
    "| 4000         | 0.640    | 0.567           |\n",
    "| 3000         | 0.645    | 0.575           |\n",
    "| 2000         | 0.655    | 0.598           |\n",
    "| 1000         | 0.657    | 0.608           |\n",
    "\n",
    "### Conclusion\n",
    "- Reducing `max_features` to **1000–2000** improves model performance, especially weighted F1-score and accuracy.  \n",
    "- A smaller vocabulary focuses on the most important features and reduces noise.  \n",
    "- Very high max_features (9000–10000) does not necessarily improve performance.  \n",
    "\n",
    "### Recommendations / Next Steps\n",
    "- Consider combining **TF-IDF (max_features=1000–2000)** with hyperparameter tuning for RandomForest (n_estimators, max_depth, min_samples_split).  \n",
    "- Test other classifiers like **XGBoost or LGBM** on this optimized feature set.  \n",
    "- Evaluate the model on **class imbalance metrics** to ensure minority classes (-1) are reasonably predicted.  \n",
    "\n",
    "### Artifacts\n",
    "- Confusion matrix plots  \n",
    "- Trained model pickle files  \n",
    "- Dataset CSV  \n",
    "- MLflow logs for experiment tracking  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd589bc-57d6-4c94-aff3-aa3d0c49cf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube-comment_Experiments",
   "language": "python",
   "name": "youtube-comment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
